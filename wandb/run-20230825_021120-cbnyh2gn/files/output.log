/home/rick/mambaforge/envs/DMD/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/rick/mambaforge/envs/DMD/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory /home/rick/projects/DMD_waights exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name  | Type       | Params
-------------------------------------
0 | model | Voxel2Mesh | 8.5 M
-------------------------------------
8.5 M     Trainable params
23.2 K    Non-trainable params
8.5 M     Total params
34.109    Total estimated model params size (MB)



Epoch 0:   0%|                                                                                                                                                         | 0/10 [00:00<?, ?it/s]
[34m[1mwandb[39m[22m: Ctrl + C detected. Stopping sweep.